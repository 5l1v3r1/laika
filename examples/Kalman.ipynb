{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this example we will show the difference between fixes computed with laika\n",
    "# from raw data of the ublox receiver vs the the fixes the ublox receiver\n",
    "# computes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We import the saved data\n",
    "\n",
    "import numpy as np\n",
    "with open('kalman_example_data', 'r') as f:\n",
    "  raw_ublox_t, raw_ublox, ublox_fixes_t, ublox_fixes = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We get the raw data into our format from the log array format\n",
    "\n",
    "from laika.gnss.raw_gnss import normal_meas_from_array\n",
    "measurements = np.array([normal_meas_from_array(arr) for arr in raw_ublox])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize an astrodog with dgps corrections\n",
    "\n",
    "from laika.gnss.astro_dog import AstroDog\n",
    "dog = AstroDog(dgps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling from http://ftpcache.comma.life/ftp-glonass-iac-ru/MCC/PRODUCTS/18186/final/Sta20084.sp3 to /tmp/gnss/russian_products/18186/final/Sta20084.sp3\n",
      "pulling from http://ftpcache.comma.life/ftp-glonass-iac-ru/MCC/PRODUCTS/18187/final/Sta20085.sp3 to /tmp/gnss/russian_products/18187/final/Sta20085.sp3\n",
      "pulling from http://ftpcache.comma.life/ftp-glonass-iac-ru/MCC/PRODUCTS/18188/final/Sta20086.sp3 to /tmp/gnss/russian_products/18188/final/Sta20086.sp3\n",
      "No orbit data found for prn : G04 flagging as bad\n",
      "No orbit data found for prn : R06 flagging as bad\n",
      "No orbit data found for prn : R12 flagging as bad\n",
      "No orbit data found for prn : R25 flagging as bad\n",
      "No orbit data found for prn : R27 flagging as bad\n",
      "No orbit data found for prn : R28 flagging as bad\n",
      "pulling from http://ftpcache.comma.life/geodesy-noaa-gov/cors/rinex/2018/187/hsib/hsib1870.18o.gz to /tmp/gnss/cors_obs/2018/187/hsib/hsib1870.18o\n",
      "  download failed HTTP Error 404: NOT FOUND\n",
      "pulling from http://ftpcache.comma.life/geodesy-noaa-gov/cors/rinex/2018/187/pbl1/pbl11870.18o.gz to /tmp/gnss/cors_obs/2018/187/pbl1/pbl11870.18o\n",
      "  download failed HTTP Error 404: NOT FOUND\n",
      "pulling from http://ftpcache.comma.life/geodesy-noaa-gov/cors/rinex/2018/187/pbl2/pbl21870.18o.gz to /tmp/gnss/cors_obs/2018/187/pbl2/pbl21870.18o\n",
      "  download failed HTTP Error 404: NOT FOUND\n",
      "pulling from http://ftpcache.comma.life/geodesy-noaa-gov/cors/rinex/2018/187/tibb/tibb1870.18o.gz to /tmp/gnss/cors_obs/2018/187/tibb/tibb1870.18o\n",
      "pulling from http://ftpcache.comma.life/cddis-gsfc-nasa-gov/gnss/products/ionex/2018/187/codg1870.18i.Z to /tmp/gnss/ionex/2018/187/codg1870.18i\n",
      "pulling from http://ftpcache.comma.life/cddis-nasa-gov/gnss/products/bias/2018/CAS0MGXRAP_20181870000_01D_01D_DCB.BSX.gz to /tmp/gnss/dcb/2018/CAS0MGXRAP_20181870000_01D_01D_DCB.BSX\n",
      "No dcb data found for prn : R26 flagging as bad\n",
      "pulling from http://ftpcache.comma.life/geodesy-noaa-gov/cors/rinex/2018/187/capo/capo1870.18o.gz to /tmp/gnss/cors_obs/2018/187/capo/capo1870.18o\n",
      "pulling from http://ftpcache.comma.life/geodesy-noaa-gov/cors/rinex/2018/187/p181/p1811870.18o.gz to /tmp/gnss/cors_obs/2018/187/p181/p1811870.18o\n"
     ]
    }
   ],
   "source": [
    "from laika.gnss.raw_gnss import process_measurements, correct_measurements, calc_pos_fix\n",
    "\n",
    "# We want to group measurements by measurement epoch\n",
    "# this makes the kalman filter faster and is easier\n",
    "# to reason about\n",
    "grouped_t = sorted(list(set(raw_ublox_t)))                                                                                      \n",
    "grouped_meas_processed = []\n",
    "corrected_meas_arrays = []\n",
    "\n",
    "# process measurement groups\n",
    "for t in grouped_t:\n",
    "  meas = measurements[raw_ublox_t == t]\n",
    "  grouped_meas_processed.append(process_measurements(meas, dog))\n",
    "\n",
    "# correct measurement groups with an estimate position\n",
    "# that was computes with weighted-least-squares on\n",
    "# the first epoch\n",
    "wls_estimate = calc_pos_fix(grouped_meas_processed[0])\n",
    "est_pos = wls_estimate[0][:3]\n",
    "for proc in grouped_meas_processed:\n",
    "  corrected = correct_measurements(proc, est_pos, dog)\n",
    "  corrected_meas_arrays.append(np.array([c.as_array() for c in corrected]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:00<00:00, 1568.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# We run the kalman filter\n",
    "\n",
    "from selfdrive.locationd.kalman.gnss_kf import GNSSKalman\n",
    "from selfdrive.locationd.kalman.kalman_helpers import run_car_ekf_offline, ObservationKind\n",
    "ekf = GNSSKalman()\n",
    "init_state = ekf.x\n",
    "init_state[:3] = est_pos\n",
    "ekf.init_state(init_state)\n",
    "ekf_data = {}\n",
    "ekf_data[ObservationKind.PSEUDORANGE_GPS] = (grouped_t, corrected_meas_arrays)\n",
    "ekf_data[ObservationKind.PSEUDORANGE_RATE_GPS] = (grouped_t, corrected_meas_arrays)\n",
    "ekf_outputs = run_car_ekf_offline(ekf, ekf_data)\n",
    "\n",
    "import common.transformations.coordinates as coord\n",
    "laika_positions_t = ekf_outputs[4]\n",
    "laika_positions_ecef = ekf_outputs[0][:,:3]\n",
    "laika_positions_geodetic = coord.ecef2geodetic(laika_positions_ecef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ublox_positions_geodetic = ublox_fixes[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By looking at the map, we can see that the ublox fix positions\n",
    "# are almost a full lane of and not even on the road anymore.\n",
    "# If you want to regenerate the gmplot you will need a google\n",
    "# maps API key\n",
    "'''\n",
    "import gmplot\n",
    "gmap = gmplot.GoogleMapPlotter(*laika_positions_geo[0])\n",
    "gmap.apikey='AIzaSyDgHRKt45t1-SMDa8Qfp8xjJWtOFVY_sSk'\n",
    "gmap.plot([x[0]  for x in laika_positions_ecef], [x[1] for x in laika_positions_ecef], 'blue', edge_width = 5)\n",
    "gmap.plot([x[0]  for x in ublox_positions_geodetic], [x[1] for x in ublox_positions_geodetic], 'red', edge_width = 5)\n",
    "gmap.draw(\"laika_quality_check.html\")\n",
    "'''\n",
    "\n",
    "\n",
    "import webbrowser\n",
    "import os\n",
    "webbrowser.open('file://' + os.path.realpath(\"laika_quality_check.html\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
